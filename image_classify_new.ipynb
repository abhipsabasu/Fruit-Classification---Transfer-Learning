{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "image_classify_new.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBelkJupFYSq",
        "colab_type": "text"
      },
      "source": [
        "**Fruit Classification**: An exercise involving transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqVhPqYsJeFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60849d1f-88c5-48e8-b07b-1ab08ebbcc06"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount = True)\n",
        "dataset_path = 'gdrive/My Drive/Deep Learning/Fruit Classification'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO0g1CmOH6Sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn0aTfBNH6Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = dataset_path + \"/data/test\"\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwsNSuv6H6Sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 128 # All images will be resized to 224 x 224\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMoWu5JLFzQb",
        "colab_type": "text"
      },
      "source": [
        "**Keras' Image Datagenerator**: Performs data augmentation accoring to the parameters given, which can be determined based on the results obtained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQfGCEymH6Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,rotation_range=30,horizontal_flip=True,vertical_flip = True,validation_split =0.1)\n",
        "#train_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function = preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WmUg-hV0Qp3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "fc9ab32b-3988-4649-99bf-38c39d92e6f1"
      },
      "source": [
        "import glob\n",
        "data = glob.glob('gdrive/My Drive/Deep Learning/*')\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gdrive/My Drive/Deep Learning/MNIST with CNN', 'gdrive/My Drive/Deep Learning/Char Prediction', 'gdrive/My Drive/Deep Learning/sentiment analysis', 'gdrive/My Drive/Deep Learning/Pneumothorax', 'gdrive/My Drive/Deep Learning/Fruit Classification']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx1AkseFGXLs",
        "colab_type": "text"
      },
      "source": [
        "The next two cells generate the train and validation images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgscfFskH6S0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "31c35261-1d69-4ccb-e9ad-b44675ffff38"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "                train_dir,  # Source directory for the training images\n",
        "                batch_size=batch_size,\n",
        "                target_size=(image_size, image_size),\n",
        "                class_mode='categorical',\n",
        "                subset = 'training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10802 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQk_-OQ0H6S5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fdc399ce-94a8-483d-8a2a-52d6844fea66"
      },
      "source": [
        "validation_generator = train_datagen.flow_from_directory(\n",
        "                train_dir, # Source directory for the validation images\n",
        "                batch_size=batch_size,\n",
        "                target_size=(image_size, image_size),\n",
        "                class_mode='categorical',\n",
        "                subset = 'validation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1198 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg9o1fh-H7Kz",
        "colab_type": "text"
      },
      "source": [
        "VGG16 used for transfer learning. Using Imagenet weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOs1g2zAH6S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE = (image_size, image_size, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmGcgTDkH6TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6tl1zDtIVTm",
        "colab_type": "text"
      },
      "source": [
        "To the base model, a dense layer of 1024 neurons is added, along with drop out. Finally there is the output layer of 6 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtjA5AZzH6TG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b68648f0-996f-4823-ef9a-a04e02919bab"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  keras.layers.GlobalAveragePooling2D(),\n",
        "  keras.layers.Dense(1024, activation='relu'),\n",
        "  keras.layers.Dropout(0.2),\n",
        "  keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "'''model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (image_size,image_size,3)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(6, activation = \"softmax\"))'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model = Sequential()\\n\\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = \\'Same\\', \\n                 activation =\\'relu\\', input_shape = (image_size,image_size,3)))\\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = \\'Same\\', \\n                 activation =\\'relu\\'))\\nmodel.add(MaxPool2D(pool_size=(2,2)))\\nmodel.add(Dropout(0.25))\\n\\n\\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = \\'Same\\', \\n                 activation =\\'relu\\'))\\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = \\'Same\\', \\n                 activation =\\'relu\\'))\\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\\nmodel.add(Dropout(0.25))\\n\\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = \\'Same\\', \\n                 activation =\\'relu\\'))\\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = \\'Same\\', \\n                 activation =\\'relu\\'))\\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\\nmodel.add(Dropout(0.25))\\n\\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3),padding = \\'Same\\', \\n                 activation =\\'relu\\'))\\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3),padding = \\'Same\\', \\n                 activation =\\'relu\\'))\\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\\nmodel.add(Dropout(0.25))\\n\\n\\nmodel.add(Flatten())\\nmodel.add(Dense(256, activation = \"relu\"))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(6, activation = \"softmax\"))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRFbxDf2RSMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZYhrBTQH6TX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0,amsgrad=False),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqvAZ0e9H6Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78jFlzFeH6Ti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51d0a52c-0a39-4319-be22-51c1a146a921"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "steps_per_epoch = train_generator.n // batch_size\n",
        "validation_steps = validation_generator.n // batch_size\n",
        "\n",
        "filepath= dataset_path + \"/weights-improvement-{epoch:02d}-{val_acc:.2f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch = steps_per_epoch,\n",
        "                              epochs=epochs,\n",
        "                              workers = 4,\n",
        "                              shuffle = True,\n",
        "                              callbacks=callbacks_list,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=validation_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.2902 - acc: 0.8964\n",
            "Epoch 00001: val_loss improved from inf to 0.36966, saving model to gdrive/My Drive/Deep Learning/Fruit Classification/weights-improvement-01-0.87.h5\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.2908 - acc: 0.8962 - val_loss: 0.3697 - val_acc: 0.8674\n",
            "Epoch 2/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.2505 - acc: 0.9099\n",
            "Epoch 00002: val_loss improved from 0.36966 to 0.30688, saving model to gdrive/My Drive/Deep Learning/Fruit Classification/weights-improvement-02-0.88.h5\n",
            "337/337 [==============================] - 43s 129ms/step - loss: 0.2507 - acc: 0.9098 - val_loss: 0.3069 - val_acc: 0.8775\n",
            "Epoch 3/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.2365 - acc: 0.9138\n",
            "Epoch 00003: val_loss improved from 0.30688 to 0.25860, saving model to gdrive/My Drive/Deep Learning/Fruit Classification/weights-improvement-03-0.90.h5\n",
            "337/337 [==============================] - 43s 129ms/step - loss: 0.2369 - acc: 0.9136 - val_loss: 0.2586 - val_acc: 0.9029\n",
            "Epoch 4/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.2075 - acc: 0.9222\n",
            "Epoch 00004: val_loss did not improve from 0.25860\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.2071 - acc: 0.9225 - val_loss: 0.2635 - val_acc: 0.9029\n",
            "Epoch 5/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1999 - acc: 0.9249\n",
            "Epoch 00005: val_loss did not improve from 0.25860\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.1996 - acc: 0.9251 - val_loss: 0.2836 - val_acc: 0.8834\n",
            "Epoch 6/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1873 - acc: 0.9280\n",
            "Epoch 00006: val_loss did not improve from 0.25860\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.1869 - acc: 0.9282 - val_loss: 0.3423 - val_acc: 0.8775\n",
            "Epoch 7/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1745 - acc: 0.9362\n",
            "Epoch 00007: val_loss did not improve from 0.25860\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.1744 - acc: 0.9362 - val_loss: 0.2997 - val_acc: 0.8877\n",
            "Epoch 8/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9371\n",
            "Epoch 00008: val_loss did not improve from 0.25860\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.1683 - acc: 0.9370 - val_loss: 0.2880 - val_acc: 0.8894\n",
            "Epoch 9/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9427\n",
            "Epoch 00009: val_loss improved from 0.25860 to 0.23116, saving model to gdrive/My Drive/Deep Learning/Fruit Classification/weights-improvement-09-0.90.h5\n",
            "337/337 [==============================] - 43s 129ms/step - loss: 0.1518 - acc: 0.9423 - val_loss: 0.2312 - val_acc: 0.8961\n",
            "Epoch 10/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9461\n",
            "Epoch 00010: val_loss did not improve from 0.23116\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.1454 - acc: 0.9460 - val_loss: 0.3581 - val_acc: 0.8767\n",
            "Epoch 11/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9431\n",
            "Epoch 00011: val_loss did not improve from 0.23116\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.1489 - acc: 0.9431 - val_loss: 0.2817 - val_acc: 0.8775\n",
            "Epoch 12/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1399 - acc: 0.9471\n",
            "Epoch 00012: val_loss improved from 0.23116 to 0.19071, saving model to gdrive/My Drive/Deep Learning/Fruit Classification/weights-improvement-12-0.91.h5\n",
            "337/337 [==============================] - 44s 131ms/step - loss: 0.1397 - acc: 0.9472 - val_loss: 0.1907 - val_acc: 0.9139\n",
            "Epoch 13/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9458\n",
            "Epoch 00013: val_loss did not improve from 0.19071\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.1356 - acc: 0.9458 - val_loss: 0.2207 - val_acc: 0.8902\n",
            "Epoch 14/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9519\n",
            "Epoch 00014: val_loss did not improve from 0.19071\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.1262 - acc: 0.9520 - val_loss: 0.1920 - val_acc: 0.9079\n",
            "Epoch 15/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9501\n",
            "Epoch 00015: val_loss improved from 0.19071 to 0.17204, saving model to gdrive/My Drive/Deep Learning/Fruit Classification/weights-improvement-15-0.92.h5\n",
            "337/337 [==============================] - 45s 134ms/step - loss: 0.1264 - acc: 0.9502 - val_loss: 0.1720 - val_acc: 0.9223\n",
            "Epoch 16/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9529\n",
            "Epoch 00016: val_loss did not improve from 0.17204\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.1244 - acc: 0.9526 - val_loss: 0.1869 - val_acc: 0.9341\n",
            "Epoch 17/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9534\n",
            "Epoch 00017: val_loss did not improve from 0.17204\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.1168 - acc: 0.9534 - val_loss: 0.2567 - val_acc: 0.8775\n",
            "Epoch 18/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9546\n",
            "Epoch 00018: val_loss did not improve from 0.17204\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.1134 - acc: 0.9545 - val_loss: 0.2134 - val_acc: 0.9054\n",
            "Epoch 19/50\n",
            "335/337 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9533\n",
            "Epoch 00019: val_loss did not improve from 0.17204\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.1169 - acc: 0.9531 - val_loss: 0.1990 - val_acc: 0.9147\n",
            "Epoch 20/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9541\n",
            "Epoch 00020: val_loss did not improve from 0.17204\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.1118 - acc: 0.9539 - val_loss: 0.2850 - val_acc: 0.8767\n",
            "Epoch 21/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9548\n",
            "Epoch 00021: val_loss did not improve from 0.17204\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.1087 - acc: 0.9546 - val_loss: 0.1748 - val_acc: 0.9130\n",
            "Epoch 22/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9603\n",
            "Epoch 00022: val_loss improved from 0.17204 to 0.15256, saving model to gdrive/My Drive/Deep Learning/Fruit Classification/weights-improvement-22-0.93.h5\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.0941 - acc: 0.9602 - val_loss: 0.1526 - val_acc: 0.9333\n",
            "Epoch 23/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9575\n",
            "Epoch 00023: val_loss did not improve from 0.15256\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.1001 - acc: 0.9577 - val_loss: 0.1837 - val_acc: 0.9071\n",
            "Epoch 24/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9593\n",
            "Epoch 00024: val_loss did not improve from 0.15256\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.0986 - acc: 0.9592 - val_loss: 0.1813 - val_acc: 0.9113\n",
            "Epoch 25/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9633\n",
            "Epoch 00025: val_loss improved from 0.15256 to 0.14929, saving model to gdrive/My Drive/Deep Learning/Fruit Classification/weights-improvement-25-0.94.h5\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.0907 - acc: 0.9633 - val_loss: 0.1493 - val_acc: 0.9434\n",
            "Epoch 26/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9601\n",
            "Epoch 00026: val_loss did not improve from 0.14929\n",
            "337/337 [==============================] - 43s 129ms/step - loss: 0.0967 - acc: 0.9603 - val_loss: 0.1860 - val_acc: 0.9122\n",
            "Epoch 27/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9605\n",
            "Epoch 00027: val_loss did not improve from 0.14929\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.0936 - acc: 0.9606 - val_loss: 0.1515 - val_acc: 0.9274\n",
            "Epoch 28/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9604\n",
            "Epoch 00028: val_loss did not improve from 0.14929\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.0911 - acc: 0.9604 - val_loss: 0.2036 - val_acc: 0.9088\n",
            "Epoch 29/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9567\n",
            "Epoch 00029: val_loss improved from 0.14929 to 0.09833, saving model to gdrive/My Drive/Deep Learning/Fruit Classification/weights-improvement-29-0.97.h5\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.0986 - acc: 0.9567 - val_loss: 0.0983 - val_acc: 0.9696\n",
            "Epoch 30/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9624\n",
            "Epoch 00030: val_loss did not improve from 0.09833\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.0883 - acc: 0.9621 - val_loss: 0.1742 - val_acc: 0.9096\n",
            "Epoch 31/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9638\n",
            "Epoch 00031: val_loss did not improve from 0.09833\n",
            "337/337 [==============================] - 43s 127ms/step - loss: 0.0854 - acc: 0.9638 - val_loss: 0.1414 - val_acc: 0.9215\n",
            "Epoch 32/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9619\n",
            "Epoch 00032: val_loss did not improve from 0.09833\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.0874 - acc: 0.9619 - val_loss: 0.2034 - val_acc: 0.9155\n",
            "Epoch 33/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9641\n",
            "Epoch 00033: val_loss did not improve from 0.09833\n",
            "337/337 [==============================] - 44s 129ms/step - loss: 0.0821 - acc: 0.9642 - val_loss: 0.1331 - val_acc: 0.9274\n",
            "Epoch 34/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9626\n",
            "Epoch 00034: val_loss did not improve from 0.09833\n",
            "337/337 [==============================] - 43s 128ms/step - loss: 0.0797 - acc: 0.9626 - val_loss: 0.1084 - val_acc: 0.9333\n",
            "Epoch 35/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9679\n",
            "Epoch 00035: val_loss did not improve from 0.09833\n",
            "337/337 [==============================] - 44s 131ms/step - loss: 0.0752 - acc: 0.9680 - val_loss: 0.1009 - val_acc: 0.9603\n",
            "Epoch 36/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9640\n",
            "Epoch 00036: val_loss improved from 0.09833 to 0.09197, saving model to gdrive/My Drive/Deep Learning/Fruit Classification/weights-improvement-36-0.97.h5\n",
            "337/337 [==============================] - 44s 131ms/step - loss: 0.0807 - acc: 0.9641 - val_loss: 0.0920 - val_acc: 0.9713\n",
            "Epoch 37/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9666\n",
            "Epoch 00037: val_loss did not improve from 0.09197\n",
            "337/337 [==============================] - 44s 132ms/step - loss: 0.0738 - acc: 0.9667 - val_loss: 0.1675 - val_acc: 0.9206\n",
            "Epoch 38/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9682\n",
            "Epoch 00038: val_loss did not improve from 0.09197\n",
            "337/337 [==============================] - 44s 131ms/step - loss: 0.0758 - acc: 0.9682 - val_loss: 0.1463 - val_acc: 0.9223\n",
            "Epoch 39/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9658\n",
            "Epoch 00039: val_loss did not improve from 0.09197\n",
            "337/337 [==============================] - 45s 134ms/step - loss: 0.0771 - acc: 0.9657 - val_loss: 0.1454 - val_acc: 0.9282\n",
            "Epoch 40/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9654\n",
            "Epoch 00040: val_loss did not improve from 0.09197\n",
            "337/337 [==============================] - 45s 135ms/step - loss: 0.0782 - acc: 0.9654 - val_loss: 0.1256 - val_acc: 0.9248\n",
            "Epoch 41/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9672\n",
            "Epoch 00041: val_loss did not improve from 0.09197\n",
            "337/337 [==============================] - 45s 134ms/step - loss: 0.0739 - acc: 0.9673 - val_loss: 0.1238 - val_acc: 0.9409\n",
            "Epoch 42/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9670\n",
            "Epoch 00042: val_loss did not improve from 0.09197\n",
            "337/337 [==============================] - 45s 134ms/step - loss: 0.0718 - acc: 0.9669 - val_loss: 0.1032 - val_acc: 0.9603\n",
            "Epoch 43/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9640\n",
            "Epoch 00043: val_loss did not improve from 0.09197\n",
            "337/337 [==============================] - 44s 130ms/step - loss: 0.0794 - acc: 0.9639 - val_loss: 0.1087 - val_acc: 0.9383\n",
            "Epoch 44/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9668\n",
            "Epoch 00044: val_loss did not improve from 0.09197\n",
            "337/337 [==============================] - 44s 131ms/step - loss: 0.0709 - acc: 0.9668 - val_loss: 0.1535 - val_acc: 0.9189\n",
            "Epoch 45/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9692\n",
            "Epoch 00045: val_loss improved from 0.09197 to 0.07368, saving model to gdrive/My Drive/Deep Learning/Fruit Classification/weights-improvement-45-0.98.h5\n",
            "337/337 [==============================] - 45s 134ms/step - loss: 0.0692 - acc: 0.9693 - val_loss: 0.0737 - val_acc: 0.9780\n",
            "Epoch 46/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9710\n",
            "Epoch 00046: val_loss did not improve from 0.07368\n",
            "337/337 [==============================] - 46s 135ms/step - loss: 0.0669 - acc: 0.9711 - val_loss: 0.1867 - val_acc: 0.9164\n",
            "Epoch 47/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9722\n",
            "Epoch 00047: val_loss did not improve from 0.07368\n",
            "337/337 [==============================] - 46s 136ms/step - loss: 0.0635 - acc: 0.9723 - val_loss: 0.1007 - val_acc: 0.9383\n",
            "Epoch 48/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9692\n",
            "Epoch 00048: val_loss did not improve from 0.07368\n",
            "337/337 [==============================] - 46s 135ms/step - loss: 0.0677 - acc: 0.9692 - val_loss: 0.1204 - val_acc: 0.9257\n",
            "Epoch 49/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9665\n",
            "Epoch 00049: val_loss did not improve from 0.07368\n",
            "337/337 [==============================] - 46s 135ms/step - loss: 0.0706 - acc: 0.9665 - val_loss: 0.1508 - val_acc: 0.9164\n",
            "Epoch 50/50\n",
            "336/337 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9682\n",
            "Epoch 00050: val_loss did not improve from 0.07368\n",
            "337/337 [==============================] - 45s 134ms/step - loss: 0.0652 - acc: 0.9682 - val_loss: 0.1061 - val_acc: 0.9468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmS1QS2OH6Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('mymodel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKGDJBGYH6Tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "27fef69d-dda4-45d7-8e31-073857de57b1"
      },
      "source": [
        "#from tf.keras.models import load_model\n",
        "import tensorflow\n",
        "model = tensorflow.keras.models.load_model(dataset_path+'/weights-improvement-36-0.97.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0824 19:01:12.590719 140212026992512 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0824 19:01:12.592272 140212026992512 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSgaurYjH6Tu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa997822-fd53-40c6-f3cc-c51ec16bcaea"
      },
      "source": [
        "test_dir = validation_dir\n",
        "\n",
        "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir, target_size = (image_size,image_size),batch_size=32,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 18000 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EVMdek7H6Tx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "0a46419f-46e1-48a6-85ae-7a9d8ee19d52"
      },
      "source": [
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "\n",
        "pred=model.predict_generator(test_generator,verbose=1)\n",
        "\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "\n",
        "labels = (train_generator.class_indices)\n",
        "\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "\n",
        "predictions = [labels[k] for k in predicted_class_indices]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 57/563 [==>...........................] - ETA: 55s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-dfe3316e4ede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mSTEP_SIZE_TEST\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredicted_class_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m         callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m   def _validate_compile_param_for_distribution_strategy(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GO8dTyUH6Tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = [file.split('/')[-1] for file in test_generator.filenames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKcm2ML_H6T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl70fa12H6T9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.DataFrame({\"file_id\":files,\"prediction\":predictions})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvWS-rTWH6UI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result.to_csv(dataset_path+\"output_vgg_96.csv\",header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSjZ6oAMH6UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}